[
	{
		"model": "meta-llama/Llama-3.2-1B",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 32,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 576
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 272
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 112
                                }
			]
			
		},
		"quantize": []
	},
	{
		"model": "meta-llama/Llama-3.2-3B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 64,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 144
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 96
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 40
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "meta-llama/Llama-2-7b-chat-hf",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 58
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 48
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 12
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "meta-llama/Llama-3.1-8B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 52
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 52
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 20
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "meta-llama/Llama-2-13b-chat-hf",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 192,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 44
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 20
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 8
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "Qwen/Qwen2.5-1.5B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 32,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 384
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 256
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 92
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "Qwen/Qwen2.5-7B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 64
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 64
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 24
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "Qwen/Qwen2.5-14B-Instruct-1M",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 192,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 40
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 24
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 8
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "tiiuae/Falcon3-1B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 32,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 360
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 264
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 96
                                }
			]
			
		},
		"quantize": []
	},
	{
		"model": "tiiuae/Falcon3-3B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 64,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 216
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 128
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 44
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "tiiuae/Falcon3-7B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 58
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 48
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 24
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "tiiuae/Falcon3-10B-Instruct",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 192,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 56
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 52
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 12
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "mistralai/Ministral-8B-Instruct-2410",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 56
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 40
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 8
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "EleutherAI/gpt-j-6b",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 768,
					"concurrency": 104
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 768,
					"concurrency": 24
				}
			]
		},
		"quantize": []
	},
	{
		"model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 32,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 384
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 256
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 92
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 128,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 64
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 64
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 24
                                }
			]
		},
		"quantize": []
	},
	{
		"model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
		"dtype": "bfloat16",
		"test_parameters": {
			"kv_cache": 192,
			"token_combinations": [
				{
					"inp_tokens": 128,
					"op_tokens": 1024,
					"concurrency": 28
				},
				{
					"inp_tokens": 1024,
					"op_tokens": 1024,
					"concurrency": 20
				},
                                {
                                        "inp_tokens": 2048,
                                        "op_tokens": 1024,
                                        "concurrency": 8
                                }
			]
		},
		"quantize": []
	}
]
